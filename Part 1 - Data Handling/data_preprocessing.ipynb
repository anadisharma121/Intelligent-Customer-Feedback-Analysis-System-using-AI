{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhYVRCTkQ4L9",
        "outputId": "5fe4eee7-c431-42de-f2a3-da5f6b947e70"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully!\n",
            "Number of records: 21214\n",
            "      Reviewer Name                     Profile Link Country Review Count  \\\n",
            "0        Eugene ath  /users/66e8185ff1598352d6b3701a      US     1 review   \n",
            "1  Daniel ohalloran  /users/5d75e460200c1f6a6373648c      GB    9 reviews   \n",
            "2          p fisher  /users/546cfcf1000064000197b88f      GB   90 reviews   \n",
            "3         Greg Dunn  /users/62c35cdbacc0ea0012ccaffa      AU    5 reviews   \n",
            "4     Sheila Hannah  /users/5ddbe429478d88251550610e      GB    8 reviews   \n",
            "\n",
            "                Review Date                  Rating  \\\n",
            "0  2024-09-16T13:44:26.000Z  Rated 1 out of 5 stars   \n",
            "1  2024-09-16T18:26:46.000Z  Rated 1 out of 5 stars   \n",
            "2  2024-09-16T21:47:39.000Z  Rated 1 out of 5 stars   \n",
            "3  2024-09-17T07:15:49.000Z  Rated 1 out of 5 stars   \n",
            "4  2024-09-16T18:37:17.000Z  Rated 1 out of 5 stars   \n",
            "\n",
            "                                      Review Title  \\\n",
            "0       A Store That Doesn't Want to Sell Anything   \n",
            "1           Had multiple orders one turned up andâ€¦   \n",
            "2                      I informed these reprobates   \n",
            "3  Advertise one price then increase it on website   \n",
            "4             If I could give a lower rate I would   \n",
            "\n",
            "                                         Review Text  Date of Experience  \n",
            "0  I registered on the website, tried to order a ...  September 16, 2024  \n",
            "1  Had multiple orders one turned up and driver h...  September 16, 2024  \n",
            "2  I informed these reprobates that I WOULD NOT B...  September 16, 2024  \n",
            "3  I have bought from Amazon before and no proble...  September 17, 2024  \n",
            "4  If I could give a lower rate I would! I cancel...  September 16, 2024  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    df = pd.read_csv('amazon_reviews.csv', engine='python')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "\n",
        "    print(f\"Number of records: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'amazon_reviews.csv' not found. Please make sure the file is in the correct directory.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the CSV file: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLw0hqDcSOHe",
        "outputId": "46ad4262-c2ad-4676-ae7d-ad75755cc5ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of dataframe after cleaning missing values and duplicates: (20407, 9)\n"
          ]
        }
      ],
      "source": [
        "df.dropna(subset=['Review Text'], inplace=True)\n",
        "\n",
        "df.drop_duplicates(subset=['Review Text'], inplace=True)\n",
        "\n",
        "print(f\"Shape of dataframe after cleaning missing values and duplicates: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzafW-NSRPk",
        "outputId": "b92f0ae1-26c7-44cf-a6b1-77f477c1525e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting text preprocessing...\n",
            "Preprocessing complete!\n",
            "                                         Review Text  \\\n",
            "0  I registered on the website, tried to order a ...   \n",
            "1  Had multiple orders one turned up and driver h...   \n",
            "2  I informed these reprobates that I WOULD NOT B...   \n",
            "3  I have bought from Amazon before and no proble...   \n",
            "4  If I could give a lower rate I would! I cancel...   \n",
            "\n",
            "                                 cleaned_review_text  \n",
            "0  registered website tried order laptop entered ...  \n",
            "1  multiple order one turned driver phone door nu...  \n",
            "2  informed reprobate would going visit sick rela...  \n",
            "3  bought amazon problem happy service price amaz...  \n",
            "4  could give lower rate would cancelled amazon p...  \n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    cleaned_tokens = [\n",
        "        lemmatizer.lemmatize(word) for word in tokens if word not in stop_words\n",
        "    ]\n",
        "\n",
        "    return \" \".join(cleaned_tokens)\n",
        "\n",
        "\n",
        "print(\"Starting text preprocessing...\")\n",
        "df['cleaned_review_text'] = df['Review Text'].apply(preprocess_text)\n",
        "print(\"Preprocessing complete!\")\n",
        "\n",
        "print(df[['Review Text', 'cleaned_review_text']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qao2ewMySpp8",
        "outputId": "e825cb82-b0ca-4f7e-e982-43da8a952a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned dataset saved as 'cleaned_amazon_reviews.csv'\n"
          ]
        }
      ],
      "source": [
        "final_df = df[['Rating', 'Review Text', 'cleaned_review_text']]\n",
        "\n",
        "final_df.to_csv('cleaned_amazon_reviews.csv', index=False)\n",
        "\n",
        "print(\"Cleaned dataset saved as 'cleaned_amazon_reviews.csv'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
